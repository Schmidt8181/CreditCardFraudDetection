{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection:\n",
    "## Exploring different models for fraud detection\n",
    "\n",
    "In this notebook, we will be exploring a 2013 dataset of credit card transactions, gathered over 2 days, with only 492 frauds out of 284,807 total transactons. The deep imbalance of the dataset will require us to modify our samples. We will test all models with both oversampling sets and undersampling sets. 29 of the 31 columns are anonymized features, with only 'Time' and 'Amount' being unchanged. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The focus for this notebook will be in correctly finding fraud, rather than correctly labeling non-fraud. \n",
    "\n",
    "The models we will be testing are:\n",
    "    1. Ordinary Least Squares\n",
    "    2. Ridge Regression\n",
    "    3. Random Forest\n",
    "    4. Ensemble model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdata = pd.read_csv('/Users/Beba/Documents/JupyterNotebooks/CreditCardFraudDetection/creditcard.csv')\n",
    "\n",
    "ccdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "ccdata['ScaledAmount'] = scaler.fit_transform(ccdata['Amount'].values.reshape(-1, 1))\n",
    "# scaling the 'Amount' column so it is in line with the rest of the PCA created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ccdata.drop(['Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>ScaledAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>3.202236e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.532294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.308401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.652715e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.471707e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.023622e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                V21           V22           V23           V24  \\\n",
       "count      ...       2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...       1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...       7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...      -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...      -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...      -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...       1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...       2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28          Class  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16       0.001727   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01       0.041527   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       0.000000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02       0.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02       0.000000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01       1.000000   \n",
       "\n",
       "       ScaledAmount  \n",
       "count  2.848070e+05  \n",
       "mean   3.202236e-16  \n",
       "std    1.000002e+00  \n",
       "min   -3.532294e-01  \n",
       "25%   -3.308401e-01  \n",
       "50%   -2.652715e-01  \n",
       "75%   -4.471707e-02  \n",
       "max    1.023622e+02  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time            0\n",
       "V1              0\n",
       "V2              0\n",
       "V3              0\n",
       "V4              0\n",
       "V5              0\n",
       "V6              0\n",
       "V7              0\n",
       "V8              0\n",
       "V9              0\n",
       "V10             0\n",
       "V11             0\n",
       "V12             0\n",
       "V13             0\n",
       "V14             0\n",
       "V15             0\n",
       "V16             0\n",
       "V17             0\n",
       "V18             0\n",
       "V19             0\n",
       "V20             0\n",
       "V21             0\n",
       "V22             0\n",
       "V23             0\n",
       "V24             0\n",
       "V25             0\n",
       "V26             0\n",
       "V27             0\n",
       "V28             0\n",
       "Class           0\n",
       "ScaledAmount    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11d02f7f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzrCRJHVn2EiSujNsJEndGTaSpO7+P2UUTCoKGPdfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cfcf390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirm class imbalance in data\n",
    "sns.countplot(\"Class\", data=ccdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x111c95080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAE6CAYAAABZICYGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEv4/oigBNlNRiLAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11023b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check for correlation with our outcome variable\n",
    "sns.heatmap(ccdata.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling, Oversampling and Undersampling of our data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampled_set(data, sample_count):\n",
    "    sampled = np.random.choice(a=data, size=sample_count)\n",
    "    return(sampled)\n",
    "\n",
    "fraud_data = np.array(ccdata[ccdata['Class']==1].index)\n",
    "honest_data = np.array(ccdata[ccdata['Class']==0].index)\n",
    "fraud_sample_index = sampled_set(fraud_data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "honest_sample_index = sampled_set(honest_data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(index_list1, index_list2, dataframe):\n",
    "    combined_indexes = np.concatenate((index_list1, index_list2))\n",
    "    located_data = dataframe.iloc[combined_indexes,:]\n",
    "    return(located_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_index = np.concatenate((fraud_sample_index, honest_sample_index))\n",
    "undersampled_data = ccdata.iloc[combined_index,:]\n",
    "sample_y = undersampled_data['Class']\n",
    "undersampled_X = undersampled_data.drop(['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oversampled_fraud_index = sampled_set(fraud_data, 100000)\n",
    "oversampled_honest_index = sampled_set(honest_data, 100000)\n",
    "oversampled_combined_index = np.concatenate((oversampled_fraud_index, oversampled_honest_index))\n",
    "oversampled_data = ccdata.iloc[oversampled_combined_index,:]\n",
    "oversampled_y = oversampled_data['Class']\n",
    "oversampled_X = oversampled_data.drop(['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = ccdata.drop(['Class'], axis=1)\n",
    "all_y = ccdata['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a tool to model and test our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_testing(model, X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scored_model_train = model.score(X_train, y_train)\n",
    "    scored_model_test = model.score(X_test, y_test)\n",
    "    model_scoreit = score_it(y_test, y_pred)\n",
    "    print(\"Model Score with Training data:\")\n",
    "    print(scored_model_train)\n",
    "    print(\"Model Score with Testing data:\")\n",
    "    print(scored_model_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scoring these thingies! \n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "def score_it(y_true, y_pred):\n",
    "    print(\"Recall Score:\")\n",
    "    print(recall_score(y_true, y_pred))\n",
    "    print(\"Precision Score:\")\n",
    "    print(precision_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\")\n",
    "    print(f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Data\n",
    "## Test a logisitc regression with our undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "0.945205479452\n",
      "Precision Score:\n",
      "0.985714285714\n",
      "F1 Score:\n",
      "0.965034965035\n",
      "Model Score with Training data:\n",
      "0.93\n",
      "Model Score with Testing data:\n",
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "logr = linear_model.LogisticRegression(C=.01)\n",
    "model_testing(logr, undersampled_X, sample_y, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing a Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "1.0\n",
      "Precision Score:\n",
      "1.0\n",
      "F1 Score:\n",
      "1.0\n",
      "Model Score with Training data:\n",
      "1.0\n",
      "Model Score with Testing data:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression here\n",
    "ridgeC = linear_model.RidgeClassifier()\n",
    "model_testing(ridgeC, undersampled_X, sample_y, .03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "0.940789473684\n",
      "Precision Score:\n",
      "1.0\n",
      "F1 Score:\n",
      "0.969491525424\n",
      "Model Score with Training data:\n",
      "0.97\n",
      "Model Score with Testing data:\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "# Random Forest here\n",
    "forest = ensemble.RandomForestClassifier(n_estimators=500, max_depth=2)\n",
    "model_testing(forest, undersampled_X, sample_y, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling the fraud data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logisitic Regression with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "0.893702353331\n",
      "Precision Score:\n",
      "0.982867349543\n",
      "F1 Score:\n",
      "0.936166519105\n",
      "Model Score with Training data:\n",
      "0.937107142857\n",
      "Model Score with Testing data:\n",
      "0.938716666667\n"
     ]
    }
   ],
   "source": [
    "model_testing(logr, oversampled_X, oversampled_y, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression Classifier with Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "1.0\n",
      "Precision Score:\n",
      "1.0\n",
      "F1 Score:\n",
      "1.0\n",
      "Model Score with Training data:\n",
      "1.0\n",
      "Model Score with Testing data:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "model_testing(ridgeC, oversampled_X, oversampled_y, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest Classifier with Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "0.928427959293\n",
      "Precision Score:\n",
      "0.999819748369\n",
      "F1 Score:\n",
      "0.962802242627\n",
      "Model Score with Training data:\n",
      "0.964535714286\n",
      "Model Score with Testing data:\n",
      "0.964283333333\n"
     ]
    }
   ],
   "source": [
    "model_testing(forest, oversampled_X, oversampled_y, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing a round with all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "0.659863945578\n",
      "Precision Score:\n",
      "0.729323308271\n",
      "F1 Score:\n",
      "0.692857142857\n",
      "Model Score with Training data:\n",
      "0.999077065067\n",
      "Model Score with Testing data:\n",
      "0.998993481034\n"
     ]
    }
   ],
   "source": [
    "model_testing(logr, all_X, all_y, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "0.427586206897\n",
      "Precision Score:\n",
      "0.826666666667\n",
      "F1 Score:\n",
      "0.563636363636\n",
      "Model Score with Training data:\n",
      "0.998861379186\n",
      "Model Score with Testing data:\n",
      "0.998876443945\n"
     ]
    }
   ],
   "source": [
    "model_testing(ridgeC, all_X, all_y, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:\n",
      "0.570469798658\n",
      "Precision Score:\n",
      "0.867346938776\n",
      "F1 Score:\n",
      "0.688259109312\n",
      "Model Score with Training data:\n",
      "0.999092112919\n",
      "Model Score with Testing data:\n",
      "0.999098814414\n"
     ]
    }
   ],
   "source": [
    "model_testing(forest, all_X, all_y, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bringing it all together\n",
    "\n",
    "We are prioritizing finding fraud over correctly labeling non-fraud. As such, we are using recall_score as our measure for these models performance.\n",
    "\n",
    "After running our models with our different sets of sampled data, and the full data set, we find that Ridge Classifier provides us with the highest recall score. The score is 1.0 on a 0-1 scale, and all the scores for that model returned a 1, making me suspicious of the accuracy of the score. The next best score of .9452 was earned by Logistic Regression with undersampled X data, and C=.01. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
